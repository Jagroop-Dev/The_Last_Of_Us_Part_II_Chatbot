{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1864a8-7fa0-4113-a43b-c90ccfaf858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import json\n",
    "import ast # Import ast for literal_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba6e4b6-0621-40f5-8d4d-cbcf7521ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images_from_csv(csv_file_path, image_url_column, subfolder):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {csv_file_path}\")\n",
    "        return\n",
    "\n",
    "    image_dir = os.path.join('Images', subfolder)\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "    print(f\"Downloading images from '{csv_file_path}' to '{image_dir}'...\")\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_url = row.get(image_url_column)\n",
    "        if pd.isna(image_url) or not isinstance(image_url, str):\n",
    "            continue \n",
    "\n",
    "        if image_url.lower().endswith(('.jpeg/show', '.png/show', '.jpg/show', '.webp/show')):\n",
    "            try:\n",
    "                response = requests.get(image_url, stream=True, headers=headers, timeout=30)\n",
    "                response.raise_for_status() \n",
    "                url_path = urlparse(image_url).path\n",
    "                if url_path.endswith('/show'):\n",
    "                    clean_path = url_path[:-5]  \n",
    "                    original_filename = os.path.basename(clean_path)\n",
    "                else:\n",
    "                    original_filename = os.path.basename(url_path)\n",
    "                \n",
    "                if not original_filename or '.' not in original_filename:\n",
    "                    content_type = response.headers.get('content-type', '')\n",
    "                    if 'jpeg' in content_type or 'jpg' in content_type:\n",
    "                        ext = '.jpg'\n",
    "                    elif 'png' in content_type:\n",
    "                        ext = '.png'\n",
    "                    elif 'webp' in content_type:\n",
    "                        ext = '.webp'\n",
    "                    else:\n",
    "                        ext = '.jpg'  \n",
    "                    original_filename = f\"image_{index}{ext}\"\n",
    "\n",
    "                filename = f\"{index}_{original_filename}\"\n",
    "                image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "                with open(image_path, 'wb') as img_file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk: \n",
    "                            img_file.write(chunk)\n",
    "\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "\n",
    "               \n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error downloading {image_url}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while processing {image_url}: {e}\")\n",
    "\n",
    "    print(f\"Finished downloading images from '{csv_file_path}'.\")\n",
    "\n",
    "\n",
    "#download_images_from_csv('chapter_data.csv', 'Chapter Image', 'Chapter_images')\n",
    "#download_images_from_csv('character_data.csv', 'Character Icon URL', 'Character_icon_images')\n",
    "#download_images_from_csv('character_data.csv', 'Character Main Image URL', 'Character_images')\n",
    "#download_images_from_csv('enemy_data.csv', 'enemy image url', 'enemy_images')\n",
    "#download_images_from_csv('tips_data.csv', 'Tip Image', 'tips_images')\n",
    "#download_images_from_csv('trophy_data.csv', 'Image URL', 'trophy_images')\n",
    "#download_images_from_csv('weapons_data.csv', 'Weapon Icon URL', 'weapon_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af671e90-5bac-4909-95cc-cd768cad6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_to_kill_df = pd.read_csv('how_to_kill_enemy.csv')\n",
    "\n",
    "for index, row in how_to_kill_df.iterrows():\n",
    "    enemy_name = row['Enemy name']\n",
    "    how_to_kill_guide_str = row['How to Kill Guide']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9799a5a4-f2b8-417f-8d15-015554036328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Runners_0_0_e6cb795c9598aab56dcfac299e254ea7.jpeg\n",
      "Downloaded: Runners_0_1_b28115a05f1fe7505b9c5c84311fc827.jpeg\n",
      "Downloaded: Runners_0_2_356739c8b19ba518de77382119f06bfb.jpeg\n",
      "Downloaded: Runners_0_3_1585ee707a412239544f597ff23b3365.jpeg\n",
      "Downloaded: Stalkers_1_0_e72f76b3a6874dec3fcee44426f1ec07.jpeg\n",
      "Downloaded: Stalkers_1_1_170c4e80530f3793dfcd94c96f417687.jpeg\n",
      "Downloaded: Stalkers_1_2_645ff0ce0cbffc36c107aa36f557a591.jpeg\n",
      "Downloaded: Stalkers_1_3_5f2bc1698a44c9ba76e0849fecfad7f0.jpeg\n",
      "Downloaded: Clickers_2_0_0515a1c04f337ba05458b43745fa6c1d.jpeg\n",
      "Downloaded: Clickers_2_1_e614eab058d2b82e5e5337332a3b1a9f.jpeg\n",
      "Downloaded: Bloaters_3_0_1bafae84a1dd4796f556f1ea53751ecf.jpeg\n",
      "Downloaded: Bloaters_3_1_39e8a8575d63662fa6d7df1f50ff8481.jpeg\n",
      "Downloaded: Bloaters_3_2_9faf6b02140ab7aeae766f53126f5c2a.jpeg\n",
      "Downloaded: Bloaters_3_3_eaed3156f84ed3f51ffa3cc918933442.jpeg\n",
      "Downloaded: Bloaters_3_4_d8d2266ebe6c4425ddea998b0eb53990.jpeg\n",
      "Downloaded: Shamblers_4_0_bedcc8bb79b5be7c4714ab8c1a811895.jpeg\n",
      "Downloaded: Shamblers_4_1_fedc9a2d38eba400b945fe34a069a49c.jpeg\n",
      "Downloaded: Shamblers_4_2_9e7f76f3aebee8d090a1d439c542f8cb.jpeg\n",
      "Downloaded: Shamblers_4_3_92775111947ac909fcc884157e864fd5.jpeg\n",
      "Downloaded: The_Rat_King_5_0_cfa4bccebaa68c78d868619f322feb22.jpeg\n",
      "Downloaded: The_Rat_King_5_1_a1f1cd5b3b1252ce9ca49ab817465f6f.jpeg\n",
      "Downloaded: The_Rat_King_5_2_ca598dff4b30ad1dd552db06dd47fda7.jpeg\n",
      "Downloaded: The_Rat_King_5_3_7edbc00f4b647b929f342663635a019c.jpeg\n",
      "Downloaded: The_Rat_King_5_4_56de4aaf4771318fe81d9d007180d209.jpeg\n",
      "Downloaded: The_Rat_King_5_5_30b2bea8143cd33217ca74fe355ae4ef.jpeg\n",
      "Downloaded: The_Rat_King_5_6_fe26d8ac7d70574756e883bc05bf7c09.jpeg\n",
      "Downloaded: The_Rat_King_5_7_d6ab2a5252a90c7189252d2a9caf10cf.jpeg\n",
      "Downloaded: Dogs_7_0_0999b1361b36cb3fc06141d3af61d724.jpeg\n",
      "Downloaded: Rattlers_9_0_c784d69bcbc4162c084a77946ce0fe80.jpeg\n",
      "Downloaded: Rattlers_9_1_1e8e76ece83e4ec224cb1466d8a9f4d1.jpeg\n",
      "Downloaded: Rattlers_9_2_e30bcab02cb493178fbf8ad48b5f5b61.jpeg\n",
      "Finished processing How to Kill guides and downloading images.\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory for saving images\n",
    "base_image_dir = os.path.join('Images', 'How_to_kill_enemy_images')\n",
    "if not os.path.exists(base_image_dir):\n",
    "    os.makedirs(base_image_dir)\n",
    "\n",
    "# Headers to mimic a real browser and avoid being blocked\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "for index, row in how_to_kill_df.iterrows():\n",
    "    enemy_name = row['Enemy name']\n",
    "    how_to_kill_guide_str = row['How to Kill Guide']\n",
    "\n",
    "    # Handle cases where the guide data is an error message or not a valid dictionary string\n",
    "    if not how_to_kill_guide_str or how_to_kill_guide_str.startswith('Error'):\n",
    "        print(f\"Skipping image extraction for '{enemy_name}' due to missing or error guide data.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Convert the string representation of the dictionary back to a dictionary\n",
    "        # Use ast.literal_eval for safer evaluation if json.loads fails due to nuances\n",
    "        # However, given the structure, json.loads might work if the string is properly formatted JSON\n",
    "        # Let's try json.loads first and fallback if needed, or handle potential errors\n",
    "        try:\n",
    "            how_to_kill_guide_dict = json.loads(how_to_kill_guide_str.replace(\"'\", \"\\\"\")) # Replace single quotes with double for JSON compatibility\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback to ast.literal_eval if JSON parsing fails\n",
    "            import ast\n",
    "            how_to_kill_guide_dict = ast.literal_eval(how_to_kill_guide_str)\n",
    "\n",
    "\n",
    "        # Extract image URLs from the dictionary structure\n",
    "        # The structure is a dictionary where keys are headings and values are lists of content dictionaries\n",
    "        image_urls = []\n",
    "        for heading, content_list in how_to_kill_guide_dict.items():\n",
    "            if isinstance(content_list, list):\n",
    "                for item in content_list:\n",
    "                    if isinstance(item, dict) and item.get('type') == 'image' and 'url' in item:\n",
    "                        image_urls.append(item['url'])\n",
    "\n",
    "        # Download the extracted images\n",
    "        for i, image_url in enumerate(image_urls):\n",
    "            if not image_url or not image_url.startswith('http'):\n",
    "                continue # Skip if the image URL is missing or not a valid URL\n",
    "\n",
    "            try:\n",
    "                response = requests.get(image_url, stream=True, headers=headers, timeout=30)\n",
    "                response.raise_for_status() # Raise an exception for bad status codes\n",
    "\n",
    "                # Extract filename from URL\n",
    "                url_path = urlparse(image_url).path\n",
    "                if url_path.endswith('/show'):\n",
    "                    clean_path = url_path[:-5]\n",
    "                    original_filename = os.path.basename(clean_path)\n",
    "                else:\n",
    "                    original_filename = os.path.basename(url_path)\n",
    "\n",
    "                if not original_filename or '.' not in original_filename:\n",
    "                    content_type = response.headers.get('content-type', '')\n",
    "                    if 'jpeg' in content_type or 'jpg' in content_type:\n",
    "                        ext = '.jpg'\n",
    "                    elif 'png' in content_type:\n",
    "                        ext = '.png'\n",
    "                    elif 'webp' in content_type:\n",
    "                        ext = '.webp'\n",
    "                    else:\n",
    "                        ext = '.jpg'\n",
    "                    original_filename = f\"image_{index}_{i}{ext}\" # Use index and image count for unique name\n",
    "\n",
    "\n",
    "                # Construct a unique filename including enemy name, row index, and image index\n",
    "                # Sanitize enemy_name for use in filename\n",
    "                safe_enemy_name = \"\".join([c if c.isalnum() or c in (' ', '-', '_') else '' for c in enemy_name]).replace(' ', '_')\n",
    "                filename = f\"{safe_enemy_name}_{index}_{i}_{original_filename}\"\n",
    "                image_path = os.path.join(base_image_dir, filename)\n",
    "\n",
    "                with open(image_path, 'wb') as img_file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            img_file.write(chunk)\n",
    "\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "\n",
    "                # Small delay\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error downloading {image_url}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while processing {image_url}: {e}\")\n",
    "\n",
    "    except (json.JSONDecodeError, SyntaxError) as e:\n",
    "        print(f\"Error parsing guide data for '{enemy_name}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing guide for '{enemy_name}': {e}\")\n",
    "\n",
    "print(\"Finished processing How to Kill guides and downloading images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92127bdc-0b9e-4f78-b398-80d2e3192eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_codes_df = pd.read_csv('safe_codes_.csv')\n",
    "\n",
    "for index, row in safe_codes_df.iterrows():\n",
    "    location = row['Location']\n",
    "    steps_to_safe_str = row['Steps to Safe']\n",
    "\n",
    "    # The next steps will involve processing steps_to_safe_str\n",
    "    # print(f\"Processing steps for location: {location}\")\n",
    "    # print(f\"Steps data (as string): {steps_to_safe_str[:100]}...\") # Print first 100 characters to peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e5fcca-14bd-4079-a25d-07e063bd9024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Super_Market_0_0_777d5e815510bdb8ca530173b7bce0ff.jpeg\n",
      "Downloaded: Super_Market_0_1_21f8d389280d2d8bfd8d366cb0bc1bac.jpeg\n",
      "Downloaded: Super_Market_0_2_62e5595200f35bce426616a031c577b0.jpeg\n",
      "Downloaded: Super_Market_0_3_942637bc499d497b9100e95461cc79d3.jpeg\n",
      "Downloaded: Super_Market_0_4_5b2a0e0fb18f20f5f71d5dac93929239.jpeg\n",
      "Downloaded: Bank_Vault_1_0_dc0025195cee38b70794bd866ac0973b.png\n",
      "Downloaded: Bank_Vault_1_1_ad64fa5820403221a293842d13de2028.png\n",
      "Downloaded: Bank_Vault_1_2_d4f58b5e0df23d35e94d33ca87894755.jpeg\n",
      "Downloaded: Bank_Vault_1_3_0a24a4f672ee401df75c95d85538b826.jpeg\n",
      "Downloaded: Bank_Vault_1_4_76ae20ee9d55654f4227a28ffc666e59.jpeg\n",
      "Downloaded: Courthouse_2_0_c3909513bc64950314afaf5d81ba3fc7.jpeg\n",
      "Downloaded: Courthouse_2_1_eb6b7162afb277a1ca9f7518be914a28.jpeg\n",
      "Downloaded: West_Gate_2_3_0_81b1016048b9a78e4ddac70c216b681e.jpeg\n",
      "Downloaded: West_Gate_2_3_1_7af8302743e8a020a4dd4350f608856c.jpeg\n",
      "Downloaded: Thrift_Store_4_0_574b03d5bd5fd37798729f17feb47928.jpeg\n",
      "Downloaded: Thrift_Store_4_1_bb45a52a6f84938262b25a7fdee15e28.jpeg\n",
      "Downloaded: Thrift_Store_4_2_ed86014d64b4c38f04be62c0a6027faa.jpeg\n",
      "Downloaded: Auto_Repair_Shop_6_0_c5b365178633e3ee5a0b22f820762a12.jpeg\n",
      "Downloaded: Auto_Repair_Shop_6_1_7f6548de843c749d14463e519ee6e811.jpeg\n",
      "Downloaded: Apartment_7_0_7766789097259019930b96ae64cdb5dd.jpeg\n",
      "Downloaded: Apartment_7_1_e9bae8b6918fabcad9e1cec1fed4a1f9.jpeg\n",
      "Downloaded: Apartment_7_2_435def185b3d35ec33474fe51cf256ee.jpeg\n",
      "Downloaded: Westons_Pharmacy_8_0_99f801deca6437115b99924495a577ef.jpeg\n",
      "Downloaded: Westons_Pharmacy_8_1_65589eb3afeb7909f94bc5b3637160d8.jpeg\n",
      "Downloaded: First_Gate_9_0_134105a3360a0775c2cea15958f0c6ac.jpeg\n",
      "Downloaded: First_Gate_9_1_c1f006b1a1343b958500b4f5322be37c.jpeg\n",
      "Downloaded: First_Gate_9_2_45e2c2c3f458fb68b0228defee9d3507.jpeg\n",
      "Downloaded: Big_Win_Safe_10_0_ec35e077d1cbf7c1a931ebde5a106b91.jpeg\n",
      "Downloaded: Big_Win_Safe_10_1_207849e9050e2c28dc44d881f180fdcf.jpeg\n",
      "Downloaded: Big_Win_Safe_10_2_1f0f0157e9f05fb160b6122b5b750e48.jpeg\n",
      "Downloaded: Big_Win_Safe_10_3_3dc3f34f47e2697ec17eaeca51e5332f.jpeg\n",
      "Downloaded: Big_Win_Safe_10_4_0d098b87a5c3a55cf7ac330931936c71.jpeg\n",
      "Downloaded: Big_Win_Safe_10_5_cbd418a40f085783d74b7439eee79cfe.jpeg\n",
      "Downloaded: Big_Win_Safe_10_6_6ea417940ebe184811031278a4ee4bb2.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_0_856b62a7068b1f8326c4c89f7be54e86.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_1_6ede18ea0e0a2c1f9d4c12698e60f9cc.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_2_1e2c95f855879e38d35b21297e693da0.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_3_fb746fa0b54320b3a4fcaf5efc5e1761.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_4_03b0dbf94eb7d2935a1ec97466ea85d8.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_5_232e9b637c81a1ad4bc0d889034e8d84.jpeg\n",
      "Downloaded: Jasmine_Bakery_11_6_ccc543afab49c2dba116ceedbfa4678f.jpeg\n",
      "Downloaded: Boat_Control_Room_12_0_ddd145025ffc9e4c61a661d2e6f9066d.jpeg\n",
      "Downloaded: Boat_Control_Room_12_1_1b773d938a7add3fb472caa1a1754e1d.jpeg\n",
      "Downloaded: Boat_Control_Room_12_2_2aa309afaf718c678e4177bb6a30029d.jpeg\n",
      "Downloaded: Boat_Control_Room_12_3_1934592ac8efe97e5038e1f34ab1eea7.jpeg\n",
      "Downloaded: Apartment_Bedroom_13_0_a3baa742c4aa27cb820dc422b6d3ef02.jpeg\n",
      "Downloaded: Apartment_Bedroom_13_1_f56eca9663f126345608bfb79f153fcd.jpeg\n",
      "Downloaded: Apartment_Bedroom_13_2_2f99c8073c3ae237ab8b6e6d788bb0b3.jpeg\n",
      "Downloaded: Apartment_Bedroom_13_3_045a388b63d683663b6bd2d4ed2c4597.jpeg\n",
      "Downloaded: Apartment_Bedroom_13_4_ccc543afab49c2dba116ceedbfa4678f.jpeg\n",
      "Downloaded: Across_From_Gym_14_0_0fc08c2773825bcb9346cd8d00d5cec6.jpeg\n",
      "Downloaded: Across_From_Gym_14_1_f71fc7f0b661928f7b46906b54151eda.jpeg\n",
      "Downloaded: Across_From_Gym_14_2_cdcdcce749fb2ca86c58feb4e34f9656.jpeg\n",
      "Downloaded: Across_From_Gym_14_3_dd5eac6cbae58ffafa24e6d32700d676.jpeg\n",
      "Downloaded: Across_From_Gym_14_4_e4b1f6a849974df700114884fb0b9b9d.jpeg\n",
      "Downloaded: Across_From_Gym_14_5_48c2179272ce1f77c20bcf3160b52e2f.jpeg\n",
      "Finished processing Safe Codes steps and downloading images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the base directory for saving images for safe codes\n",
    "base_image_dir_safecodes = os.path.join('Images', 'safe_code_images')\n",
    "if not os.path.exists(base_image_dir_safecodes):\n",
    "    os.makedirs(base_image_dir_safecodes)\n",
    "\n",
    "# Headers to mimic a real browser and avoid being blocked\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "for index, row in safe_codes_df.iterrows():\n",
    "    location = row['Location']\n",
    "    steps_to_safe_str = row['Steps to Safe']\n",
    "\n",
    "    # Handle cases where the steps data is an error message or not a valid list string\n",
    "    if not steps_to_safe_str or steps_to_safe_str.startswith('Error'):\n",
    "        print(f\"Skipping image extraction for '{location}' due to missing or error steps data.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Convert the string representation of the list back to a list\n",
    "        # Use ast.literal_eval as the string might contain single quotes and other non-JSON elements\n",
    "        steps_to_safe_list = ast.literal_eval(steps_to_safe_str)\n",
    "\n",
    "        # Extract image URLs from the list of dictionaries structure\n",
    "        # The structure is a list where each item is a dictionary for a step, containing an 'images' key with a list of URLs\n",
    "        image_urls = []\n",
    "        if isinstance(steps_to_safe_list, list):\n",
    "            for step in steps_to_safe_list:\n",
    "                if isinstance(step, dict) and 'images' in step and isinstance(step['images'], list):\n",
    "                    for url in step['images']:\n",
    "                        if isinstance(url, str):\n",
    "                            image_urls.append(url)\n",
    "\n",
    "        # Download the extracted images\n",
    "        for i, image_url in enumerate(image_urls):\n",
    "            if not image_url or not image_url.startswith('http'):\n",
    "                continue # Skip if the image URL is missing or not a valid URL\n",
    "\n",
    "            # Filter URLs based on the specified endings\n",
    "            if image_url.lower().endswith(('.jpeg/show', '.png/show', '.jpg/show', '.webp/show')):\n",
    "                try:\n",
    "                    response = requests.get(image_url, stream=True, headers=headers, timeout=30)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes\n",
    "\n",
    "                    # Extract filename from URL path before '/show'\n",
    "                    url_path = urlparse(image_url).path\n",
    "                    if url_path.endswith('/show'):\n",
    "                        clean_path = url_path[:-5]  # Remove '/show'\n",
    "                        original_filename = os.path.basename(clean_path)\n",
    "                    else:\n",
    "                        original_filename = os.path.basename(url_path)\n",
    "\n",
    "                    # If we still don't have a proper filename, create one\n",
    "                    if not original_filename or '.' not in original_filename:\n",
    "                        # Try to get extension from Content-Type header\n",
    "                        content_type = response.headers.get('content-type', '')\n",
    "                        if 'jpeg' in content_type or 'jpg' in content_type:\n",
    "                            ext = '.jpg'\n",
    "                        elif 'png' in content_type:\n",
    "                            ext = '.png'\n",
    "                        elif 'webp' in content_type:\n",
    "                            ext = '.webp'\n",
    "                        else:\n",
    "                            ext = '.jpg'  # Default fallback\n",
    "                        original_filename = f\"image_{index}_{i}{ext}\" # Use index and image count for unique name\n",
    "\n",
    "                    # Construct a unique filename including location, row index, and image index\n",
    "                    # Sanitize location name for use in filename\n",
    "                    safe_location_name = \"\".join([c if c.isalnum() or c in (' ', '-', '_') else '' for c in location]).replace(' ', '_')\n",
    "                    filename = f\"{safe_location_name}_{index}_{i}_{original_filename}\"\n",
    "                    image_path = os.path.join(base_image_dir_safecodes, filename)\n",
    "\n",
    "                    with open(image_path, 'wb') as img_file:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                img_file.write(chunk)\n",
    "\n",
    "                    print(f\"Downloaded: {filename}\")\n",
    "\n",
    "                    # Small delay to be respectful to the server\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Error downloading {image_url}: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An unexpected error occurred while processing {image_url}: {e}\")\n",
    "\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error parsing steps data for '{location}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing steps for '{location}': {e}\")\n",
    "\n",
    "print(\"Finished processing Safe Codes steps and downloading images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484eea46-622b-4f93-9a2c-2647999075ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
